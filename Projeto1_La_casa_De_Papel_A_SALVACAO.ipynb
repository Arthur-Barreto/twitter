{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Arthur Martins de Souza Barreto\n",
    "\n",
    "Nome: Giselle Vieira de Melo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "Os gênios do crime que dominaram as telas do mundo inteiro em <em><b> La casa de Papel </b></em>  e que conquistaram várias premiações como o Emmy Internacional de melhor série dramática, além de se tornar uma das séries mais populares da IMDb possui uma boa aclamação crítica dado seu enredo sofisticado e dramas interpessoais, se tornando a série em língua não inglesa mais assistida de 2018. \n",
    "\n",
    "A partir disso, com o lançamento da primeira parte da quinta (e última) temporada no dia 03 de Setembro de 2021, é de regular tendência pelo mundo inteiro comentários no twitter, tendo até celebridades comentando sobre a série nessa rede. \n",
    "\n",
    "<center> <img src=\"imagens/Money-Heist.jpg\" width=500> <center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessa forma, por meio da categorização dos postagens dos usuários do twitter, esse projeto visa analisar os comentários a respeito da obra, como elogios e críticas diretamente relacionados à série, desconsiderando por exemplo, tweets de marcação ou sobre temas paralelos. \n",
    "\n",
    "Para tanto, o <em><b>Classificador Naive Bayes </b></em> foi utilizado!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a biblioteca dos emojis precisa ser baixada, caso não tenha baixado descomente a linha a baixo e faça o dowload\n",
    "#pip install emoji "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bibliotecas adicionais\n",
    "import re \n",
    "# para eliminar as preposições usei o link a seguir como referencia\n",
    "# https://stackoverflow.com/questions/29523254/python-remove-stop-words-from-pandas-dataframe\n",
    "import nltk \n",
    "# apra eliminar os emojis usei o seguinte link como referencia\n",
    "# https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\arthu\\Desktop\\Documentos\\Insper\\2º_Periodo\\Ciencia_dos_dados\\twitter\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'La casa de papel.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coisas q serão proibidas quando eu for preside...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agr que tô terminando de assistir la casa de p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paguem minha terapia (la casa de papel vc me p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to com pena de terminar la casa de papel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>olha, quem me segue aqui sabe o tanto que odei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevante\n",
       "0  coisas q serão proibidas quando eu for preside...          1\n",
       "1  agr que tô terminando de assistir la casa de p...          1\n",
       "2  paguem minha terapia (la casa de papel vc me p...          0\n",
       "3           to com pena de terminar la casa de papel          0\n",
       "4  olha, quem me segue aqui sabe o tanto que odei...          1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vou assistir a última temperada de la casa de ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>só quero chegar em casa e me entupir de brigad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toda vez, a gnt depois que acaba de ver la cas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@esteseverino na verdade eles se comunicavam p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>não tô chorando horrores com o final de la cas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevante\n",
       "0  vou assistir a última temperada de la casa de ...          1\n",
       "1  só quero chegar em casa e me entupir de brigad...          1\n",
       "2  toda vez, a gnt depois que acaba de ver la cas...          0\n",
       "3  @esteseverino na verdade eles se comunicavam p...          1\n",
       "4  não tô chorando horrores com o final de la cas...          0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa parte do projeto é necessário categorizar a opinião daqueles comentários no twitter relativos à aprovação da série, (mais precisamente da nova temporada).\n",
    "\n",
    "Assim, foram encontrados diversos tweets, sendo alguns destes demasiadamente vagos, onde não dava para discernir se era um comentário aprovando ou não da série La casa de papel. Nesse caso, foi considerado relevante apenas os comentários que deixavam claro a critica à série. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Funções utilizadas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\arthu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# FUNÇÕES AUXILIARES DO SISTEMA para a montagem da base de dados do treinamento\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;\\/)|,''\"\"“”@#(*]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed.lower()\n",
    "\n",
    "# função copiada do seguinte link: https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
    "def remove_emoji(string):\n",
    "    return emoji.get_emoji_regexp().sub(u'', string)\n",
    "\n",
    "# baixando as preposições\n",
    "nltk.download('stopwords')\n",
    "# definindo as preposições da lingua portuguesa\n",
    "stop = nltk.corpus.stopwords.words('portuguese')\n",
    "def segunda_limpeza(lis_tweet):\n",
    "    limpo = []\n",
    "    for pal in lis_tweet:\n",
    "        # além de verificar se a palavra não é uma preposição vamos pegar só as que tem mais de 3 letras\n",
    "        # vamos aproveitar que estamos percorrendo cada palavra e remover os emojis nesse processo\n",
    "        if pal not in stop and len(pal)>3:\n",
    "            pal = remove_emoji(pal)\n",
    "            # pode ser que a palavra seja só o emoji, vamos verificar o tamanho dela de novo,\n",
    "            # pois pode ser uma palavra vazia\n",
    "            if len(pal) > 3:\n",
    "                limpo.append(pal)\n",
    "        else:\n",
    "            pass\n",
    "    return limpo\n",
    "\n",
    "def frase_para_palavras(df):\n",
    "    '''\n",
    "    função para percorrer linha a linha uma coluna do dataframe e concatenar as palavras em uma unica lista\n",
    "    para ser usada no value_counts()\n",
    "    '''\n",
    "    data = ''\n",
    "    \n",
    "    for tweet in df:\n",
    "        # o tweet é a frase que a pessoa postou, que se encontra em cada linha da nossa coluna\n",
    "        data += tweet\n",
    "        \n",
    "    # dando o split agora, para separar por virgula\n",
    "    data = data.split()\n",
    "    # data é um vetor, podemos chamar a função de tirar preposição aqui\n",
    "    data = segunda_limpeza(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "\n",
    "## Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O classificador Naive-Bayes é da família de classificadores estatísticos baseado no Teorema de Bayes, sendo utilizado para prever a ocorrência em um texto, muito útil para esse trabalho já que estamos tratando uma sequência de tweets sobre o tema em questão \"La casa de papel\". \n",
    "\n",
    "Assim, esse classificador, ao ter um conhecimento prévio das condições - aqui dadas por relevante (1) e irrelevante (0) -  utiliza da frequência de palavras para fazer sua classificação, já que ele trata cada palavra de uma frase como um termo independente, como por exemplo: \"la casa de papel é muito bom\" é equivalente a \"é muito bom la casa de papel\".\n",
    "\n",
    "### O teorema de Bayes e as probabilidades independentes:\n",
    "\"Os eventos A e B são independentes quando o fato de ter conhecimento sobre a ocorrência de A não altera a expectativa sobre a probabilidade de ocorrência do evento B.\"\n",
    "\n",
    "Isso é muito útil para o nosso modelo já que a probabilidade de que as mesmas frases sejam ditas em postagens distintas no twitter é baixa, mas ao fazer a suposição de que cada palavra em uma frase atua de forma independente é possível se realizar os cálculos de probabilidade.\n",
    "\n",
    "### Cálculos de probabilidade\n",
    "\n",
    "- legenda:\n",
    "\n",
    "    - $P(rel)$: probabilidade do post ser relevante;\n",
    "\n",
    "    - $P(irrel)$: probabilidade do post ser irrelevante;\n",
    "\n",
    "    - $P(total)$: $P(rel)$ + $P(irrel)$\n",
    "\n",
    "    - $P(rel|total)$: \n",
    "    $$P(rel|total) = \\frac{P(total|rel) P(rel)}{P(total)}$$\n",
    "    \n",
    "    - $P(irrel|total)$: \n",
    "    $$P(irrel|total) = \\frac{P(total|irrel) P(irrel)}{P(total)}$$\n",
    "\n",
    "#### Suavização de Laplace\n",
    "Pelo cálculo das probabilidades independentes tem-se que, a partir de uma palavra, descobrir qual é a probabilidade de essa palavra está na base de dados a partir de sua frequência. Agora imagine que a palavra não está na base de dados... o que ocorre é que a probabilidade é zero, e ao realizar a multiplicação dos termos, o cálculo é anulado, não gerando nenhuma informação (o contrário do que se espera).\n",
    "\n",
    "Assim, a suavização de Laplace surge para prevenir esse caso, dado que é adicionado 1 a cada contagem, para que o denominador nunca fique nulo. Em contrapartida, é também adicionado o número de palavras totais ao divisor, o que leva a, ao realizar a divisão, gerar sempre um número menor que um. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertendo em variáveis categóricas:\n",
    "train['Treinamento'] = train['Treinamento'].astype('category')\n",
    "test['Teste'] = test['Teste'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpando pontuações do dataframe\n",
    "train['Clean']=train['Treinamento'].apply(cleanup)\n",
    "test['Clean']=test['Teste'].apply(cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vou assistir a última temperada de la casa de ...</td>\n",
       "      <td>1</td>\n",
       "      <td>vou assistir a última temperada de la casa de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>só quero chegar em casa e me entupir de brigad...</td>\n",
       "      <td>1</td>\n",
       "      <td>só quero chegar em casa e me entupir de brigad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toda vez, a gnt depois que acaba de ver la cas...</td>\n",
       "      <td>0</td>\n",
       "      <td>toda vez a gnt depois que acaba de ver la casa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@esteseverino na verdade eles se comunicavam p...</td>\n",
       "      <td>1</td>\n",
       "      <td>esteseverino na verdade eles se comunicavam pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>não tô chorando horrores com o final de la cas...</td>\n",
       "      <td>0</td>\n",
       "      <td>não tô chorando horrores com o final de la cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>acabei la casa de papel</td>\n",
       "      <td>0</td>\n",
       "      <td>acabei la casa de papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>precisamos conversar sobre o final dessa tempo...</td>\n",
       "      <td>0</td>\n",
       "      <td>precisamos conversar sobre o final dessa tempo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>eu odeio lá casa de papel, mataram a tóquio va...</td>\n",
       "      <td>1</td>\n",
       "      <td>eu odeio lá casa de papel mataram a tóquio vai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>preguiça de ver essa parte 5 de la casa de papel</td>\n",
       "      <td>0</td>\n",
       "      <td>preguiça de ver essa parte 5 de la casa de papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>la casa de papel não vai acabar nunca? não agu...</td>\n",
       "      <td>1</td>\n",
       "      <td>la casa de papel não vai acabar nunca não ague...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Relevante  \\\n",
       "0    vou assistir a última temperada de la casa de ...          1   \n",
       "1    só quero chegar em casa e me entupir de brigad...          1   \n",
       "2    toda vez, a gnt depois que acaba de ver la cas...          0   \n",
       "3    @esteseverino na verdade eles se comunicavam p...          1   \n",
       "4    não tô chorando horrores com o final de la cas...          0   \n",
       "..                                                 ...        ...   \n",
       "195                            acabei la casa de papel          0   \n",
       "196  precisamos conversar sobre o final dessa tempo...          0   \n",
       "197  eu odeio lá casa de papel, mataram a tóquio va...          1   \n",
       "198   preguiça de ver essa parte 5 de la casa de papel          0   \n",
       "199  la casa de papel não vai acabar nunca? não agu...          1   \n",
       "\n",
       "                                                 Clean  \n",
       "0    vou assistir a última temperada de la casa de ...  \n",
       "1    só quero chegar em casa e me entupir de brigad...  \n",
       "2    toda vez a gnt depois que acaba de ver la casa...  \n",
       "3    esteseverino na verdade eles se comunicavam pe...  \n",
       "4    não tô chorando horrores com o final de la cas...  \n",
       "..                                                 ...  \n",
       "195                            acabei la casa de papel  \n",
       "196  precisamos conversar sobre o final dessa tempo...  \n",
       "197  eu odeio lá casa de papel mataram a tóquio vai...  \n",
       "198   preguiça de ver essa parte 5 de la casa de papel  \n",
       "199  la casa de papel não vai acabar nunca não ague...  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post relevante\n",
    "post_rel = train.loc[(train['Relevante'] == 1)]\n",
    "# post irrelevante\n",
    "post_irrel = train.loc[(train['Relevante'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1214\n",
      "906\n",
      "2120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "886            moto\n",
       "887        guardada\n",
       "888        deitadão\n",
       "889           vendo\n",
       "890            casa\n",
       "891           papel\n",
       "892       trabalhar\n",
       "893          recebi\n",
       "894         spoiler\n",
       "895            casa\n",
       "896           papel\n",
       "897           quero\n",
       "898         cometer\n",
       "899    homicídiovou\n",
       "900      aproveitar\n",
       "901           novos\n",
       "902       episódios\n",
       "903            casa\n",
       "904           papel\n",
       "905      abafadinha\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agora precisamos quebrar o texto em palavras, usando a função aux que converter frase em palavras,\n",
    "# ao mesmo tempo, vamos retirar as preposições do código, paralelamente a conversão, melhorando a base de dados, temos:\n",
    "data_rel   = frase_para_palavras(post_rel['Clean'])\n",
    "data_irrel = frase_para_palavras(post_irrel['Clean'])\n",
    "\n",
    "# criando a serie dos posts relevantes e irrelevantes\n",
    "serie_rel = pd.Series(data_rel)\n",
    "serie_irrel = pd.Series(data_irrel)\n",
    "# Formando uma base de daddos com todas as palavras nele:\n",
    "data_total = data_rel + data_irrel\n",
    "\n",
    "#criando a serie com a base total de dados\n",
    "serie_total = pd.Series(data_total)\n",
    "\n",
    "print(len(serie_rel))\n",
    "print(len(serie_irrel))\n",
    "print(len(serie_total))\n",
    "serie_irrel.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequências absolutas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palavras em um texto são variáveis **qualitativas nominais**, portanto usaremos `value_counts()` para obter a tabela de frequências relativas e absolutas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100odeio         1\n",
       "papelia          1\n",
       "papelagora       1\n",
       "papelarturo      1\n",
       "papelassisti     1\n",
       "                ..\n",
       "facebook         1\n",
       "falando          1\n",
       "falar            1\n",
       "falecermaaano    1\n",
       "único            1\n",
       "Length: 952, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construindo a tabela de relevante e irrelevante\n",
    "tabela_rel   = serie_rel.value_counts()\n",
    "tabela_irrel = serie_irrel.value_counts()\n",
    "tabela_total = serie_total.value_counts()\n",
    "lista_serie_total = serie_total.tolist()\n",
    "elementos_nao_repetidos = set(lista_serie_total)\n",
    "elementos_nao_repetidos = pd.DataFrame(elementos_nao_repetidos).value_counts()\n",
    "elementos_nao_repetidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coisas q serão proibidas quando eu for preside...</td>\n",
       "      <td>1</td>\n",
       "      <td>coisas q serão proibidas quando eu for preside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agr que tô terminando de assistir la casa de p...</td>\n",
       "      <td>1</td>\n",
       "      <td>agr que tô terminando de assistir la casa de p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>olha, quem me segue aqui sabe o tanto que odei...</td>\n",
       "      <td>1</td>\n",
       "      <td>olha quem me segue aqui sabe o tanto que odeio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>que final fdp do lá casa de papel</td>\n",
       "      <td>1</td>\n",
       "      <td>que final fdp do lá casa de papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>final veio de lá casa de papel, meu pai amado ...</td>\n",
       "      <td>1</td>\n",
       "      <td>final veio de lá casa de papel meu pai amado o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevante  \\\n",
       "0  coisas q serão proibidas quando eu for preside...          1   \n",
       "1  agr que tô terminando de assistir la casa de p...          1   \n",
       "4  olha, quem me segue aqui sabe o tanto que odei...          1   \n",
       "6                  que final fdp do lá casa de papel          1   \n",
       "8  final veio de lá casa de papel, meu pai amado ...          1   \n",
       "\n",
       "                                               Clean  \n",
       "0  coisas q serão proibidas quando eu for preside...  \n",
       "1  agr que tô terminando de assistir la casa de p...  \n",
       "4  olha quem me segue aqui sabe o tanto que odeio...  \n",
       "6                  que final fdp do lá casa de papel  \n",
       "8  final veio de lá casa de papel meu pai amado o...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# postagens relevantes\n",
    "post_rel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paguem minha terapia (la casa de papel vc me p...</td>\n",
       "      <td>0</td>\n",
       "      <td>paguem minha terapia la casa de papel vc me paga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to com pena de terminar la casa de papel</td>\n",
       "      <td>0</td>\n",
       "      <td>to com pena de terminar la casa de papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>simplesmente devastada com esse final da 1° pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>simplesmente devastada com esse final da 1° pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ai la casa de papel me mata pqp</td>\n",
       "      <td>0</td>\n",
       "      <td>ai la casa de papel me mata pqp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>criadores de lá casa de papel deixaram mto na ...</td>\n",
       "      <td>0</td>\n",
       "      <td>criadores de lá casa de papel deixaram mto na ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Treinamento  Relevante  \\\n",
       "2   paguem minha terapia (la casa de papel vc me p...          0   \n",
       "3            to com pena de terminar la casa de papel          0   \n",
       "5   simplesmente devastada com esse final da 1° pa...          0   \n",
       "7                     ai la casa de papel me mata pqp          0   \n",
       "10  criadores de lá casa de papel deixaram mto na ...          0   \n",
       "\n",
       "                                                Clean  \n",
       "2    paguem minha terapia la casa de papel vc me paga  \n",
       "3            to com pena de terminar la casa de papel  \n",
       "5   simplesmente devastada com esse final da 1° pa...  \n",
       "7                     ai la casa de papel me mata pqp  \n",
       "10  criadores de lá casa de papel deixaram mto na ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# postagens irrelevantes\n",
    "post_irrel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A probabilidade de relevantes é: 0.573\n"
     ]
    }
   ],
   "source": [
    "p_rel = len(serie_rel)/len(serie_total)\n",
    "print('A probabilidade de relevantes é: {0:.3f}'.format(p_rel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A probabilidade de irrelevate é: 0.427\n"
     ]
    }
   ],
   "source": [
    "p_irrel = len(serie_irrel)/len(serie_total)\n",
    "print('A probabilidade de irrelevate é: {0:.3f}'.format(p_irrel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções auxiliares para a suavização de la place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantas_vezes_aparece_palavra(palavra,tabela):\n",
    "    # a função retorna o valor de vezes que a palavra aparece no seu conjunto\n",
    "    # por exemplo, quantas vezes aparece na tabela relevante?\n",
    "    # fazemos: num = tabela_rel['palavra']\n",
    "    # e retornamos esse valor\n",
    "    # por outro lado, pode não ter a palavra, por isso a suaviação de la place, quando isso ocorrer,\n",
    "    # vamos retornar 0\n",
    "    try:\n",
    "        # caso em que a palavra tem na tabela de frequencias\n",
    "        quant = tabela[palavra]\n",
    "        return quant\n",
    "    except:\n",
    "        # aqui a palavra não está na tabela de frequencias,retornamos 0\n",
    "        return 0\n",
    "    \n",
    "def laplace_smoothing(palavras_da_classe,quantidade):\n",
    "    # vamos aplicar a formula da suavização\n",
    "    num = quantidade + 1\n",
    "    den = len(palavras_da_classe) + len(elementos_nao_repetidos)\n",
    "    #den = 2193 + len(elementos_nao_repetidos)\n",
    "    laplace = num/den\n",
    "    return laplace\n",
    "\n",
    "def p_tweet(tweet,relevante):\n",
    "    # se relevante for true, calcula para relevante\n",
    "    # se for false, para irrelevante\n",
    "    p = 1\n",
    "    # quebrando o tweet a cada espaço \n",
    "    tweet_em_palavras = tweet.split()\n",
    "    \n",
    "    for palavra in tweet_em_palavras:\n",
    "        # vamos calcular o valor da frequencia absoluta da palavra\n",
    "        # para isto, usaremos a funcao quantas_vezes_aparece_palavra\n",
    "        # verificando qual classe queremos calcular p\n",
    "        \n",
    "        if relevante:\n",
    "            quant = quantas_vezes_aparece_palavra(palavra,tabela_rel)\n",
    "            p_palavra = laplace_smoothing(serie_rel,quant)\n",
    "            \n",
    "        else:\n",
    "            quant = quantas_vezes_aparece_palavra(palavra,tabela_irrel)\n",
    "            p_palavra = laplace_smoothing(serie_irrel,quant)\n",
    "            \n",
    "        p *= p_palavra\n",
    "    return p\n",
    "\n",
    "def rel_ou_irrel(tweet):\n",
    "    # vamos decidir se o tweet é relevante ou não\n",
    "    # para tal vamos aplicar o teorema de bayes\n",
    "    P_tweet_rel   = p_tweet(tweet,True)\n",
    "    P_tweet_irrel = p_tweet(tweet,False)\n",
    "    rel_bayes     = P_tweet_rel*p_rel\n",
    "    irrel_bayes   = P_tweet_irrel*p_irrel\n",
    "    #print(rel_bayes,irrel_bayes)\n",
    "    # vamos usar o mesmo criterio adotado na tabela, 1 para relevante e 0 para irrelevante\n",
    "    if rel_bayes > irrel_bayes:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>Clean</th>\n",
       "      <th>Classificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coisas q serão proibidas quando eu for preside...</td>\n",
       "      <td>1</td>\n",
       "      <td>coisas q serão proibidas quando eu for preside...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agr que tô terminando de assistir la casa de p...</td>\n",
       "      <td>1</td>\n",
       "      <td>agr que tô terminando de assistir la casa de p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paguem minha terapia (la casa de papel vc me p...</td>\n",
       "      <td>0</td>\n",
       "      <td>paguem minha terapia la casa de papel vc me paga</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to com pena de terminar la casa de papel</td>\n",
       "      <td>0</td>\n",
       "      <td>to com pena de terminar la casa de papel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>olha, quem me segue aqui sabe o tanto que odei...</td>\n",
       "      <td>1</td>\n",
       "      <td>olha quem me segue aqui sabe o tanto que odeio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>mó sacanagem esse final de la casa de papel</td>\n",
       "      <td>1</td>\n",
       "      <td>mó sacanagem esse final de la casa de papel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>recebi spoiler de la casa de papel e quero com...</td>\n",
       "      <td>0</td>\n",
       "      <td>recebi spoiler de la casa de papel e quero com...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>terminei la casa de papel e me tornei o homem ...</td>\n",
       "      <td>1</td>\n",
       "      <td>terminei la casa de papel e me tornei o homem ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>vou aproveitar pra ver os novos episódios de l...</td>\n",
       "      <td>0</td>\n",
       "      <td>vou aproveitar pra ver os novos episódios de l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>terminei de assistir lá casa de papel ,alguém ...</td>\n",
       "      <td>1</td>\n",
       "      <td>terminei de assistir lá casa de papel alguém p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Relevante  \\\n",
       "0    coisas q serão proibidas quando eu for preside...          1   \n",
       "1    agr que tô terminando de assistir la casa de p...          1   \n",
       "2    paguem minha terapia (la casa de papel vc me p...          0   \n",
       "3             to com pena de terminar la casa de papel          0   \n",
       "4    olha, quem me segue aqui sabe o tanto que odei...          1   \n",
       "..                                                 ...        ...   \n",
       "295        mó sacanagem esse final de la casa de papel          1   \n",
       "296  recebi spoiler de la casa de papel e quero com...          0   \n",
       "297  terminei la casa de papel e me tornei o homem ...          1   \n",
       "298  vou aproveitar pra ver os novos episódios de l...          0   \n",
       "299  terminei de assistir lá casa de papel ,alguém ...          1   \n",
       "\n",
       "                                                 Clean  Classificação  \n",
       "0    coisas q serão proibidas quando eu for preside...              1  \n",
       "1    agr que tô terminando de assistir la casa de p...              1  \n",
       "2     paguem minha terapia la casa de papel vc me paga              0  \n",
       "3             to com pena de terminar la casa de papel              0  \n",
       "4    olha quem me segue aqui sabe o tanto que odeio...              1  \n",
       "..                                                 ...            ...  \n",
       "295        mó sacanagem esse final de la casa de papel              1  \n",
       "296  recebi spoiler de la casa de papel e quero com...              0  \n",
       "297  terminei la casa de papel e me tornei o homem ...              1  \n",
       "298  vou aproveitar pra ver os novos episódios de l...              0  \n",
       "299  terminei de assistir lá casa de papel alguém p...              1  \n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agora vamos criar uma coluna nova, com a classificação dos tweets\n",
    "train['Classificação'] = train['Clean'].apply(rel_ou_irrel)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adição de mais tweets na base, conforme enunciado. (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a036e081e21c160afc26bb4b03f978afee4695dfefad222ea89752b41a5783e0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
