{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nome: Arthur Martins de Souza Barreto\n",
    "\n",
    "Nome: Giselle Vieira de Melo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "\n",
    "Os g√™nios do crime que dominaram as telas do mundo inteiro em <em><b> La casa de Papel </b></em>  e que conquistaram v√°rias premia√ß√µes como o Emmy Internacional de melhor s√©rie dram√°tica, al√©m de se tornar uma das s√©ries mais populares da IMDb possui uma boa aclama√ß√£o cr√≠tica dado seu enredo sofisticado e dramas interpessoais, se tornando a s√©rie em l√≠ngua n√£o inglesa mais assistida de 2018. \n",
    "\n",
    "A partir disso, com o lan√ßamento da primeira parte da quinta (e √∫ltima) temporada no dia 03 de Setembro de 2021, √© de regular tend√™ncia pelo mundo inteiro coment√°rios no twitter, tendo at√© celebridades comentando sobre a s√©rie nessa rede. \n",
    "\n",
    "<center> <img src=\"imagens/Money-Heist.jpg\" width=500> <center> "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dessa forma, por meio da categoriza√ß√£o dos postagens dos usu√°rios do twitter, esse projeto visa analisar os coment√°rios a respeito da obra, como elogios e cr√≠ticas diretamente relacionados √† s√©rie, desconsiderando por exemplo, tweets de marca√ß√£o ou sobre temas paralelos. \n",
    "\n",
    "Para tanto, o <em><b>Classificador Naive Bayes </b></em> foi utilizado!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 125,
=======
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a biblioteca dos emojis precisa ser baixada, caso n√£o tenha baixado descomente a linha a baixo e fa√ßa o dowload\n",
    "#pip install emoji "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 126,
   "source": [
    "# bibliotecas adicionais\n",
    "import re "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ],
=======
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bibliotecas adicionais\n",
    "import re \n",
    "# para eliminar as preposi√ß√µes usei o link a seguir como referencia\n",
    "# https://stackoverflow.com/questions/29523254/python-remove-stop-words-from-pandas-dataframe\n",
    "import nltk \n",
    "# apra eliminar os emojis usei o seguinte link como referencia\n",
    "# https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "c:\\Users\\gisel\\OneDrive\\Documentos\\INSPER\\Segundo Semestre\\C-DADOS\\PROJETOS\\twitter\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 128,
=======
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
   "source": [
    "filename = 'La casa de papel.xlsx'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 129,
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ],
=======
   "execution_count": 126,
   "metadata": {},
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coisas q ser√£o proibidas quando eu for preside...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agr que t√¥ terminando de assistir la casa de p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paguem minha terapia (la casa de papel vc me p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to com pena de terminar la casa de papel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>olha, quem me segue aqui sabe o tanto que odei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevante\n",
       "0  coisas q ser√£o proibidas quando eu for preside...          1\n",
       "1  agr que t√¥ terminando de assistir la casa de p...          1\n",
       "2  paguem minha terapia (la casa de papel vc me p...          0\n",
       "3           to com pena de terminar la casa de papel          0\n",
       "4  olha, quem me segue aqui sabe o tanto que odei...          1"
      ]
     },
<<<<<<< HEAD
=======
     "execution_count": 126,
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
     "metadata": {},
     "execution_count": 129
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 130,
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ],
=======
   "execution_count": 127,
   "metadata": {},
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vou assistir a √∫ltima temperada de la casa de ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s√≥ quero chegar em casa e me entupir de brigad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toda vez, a gnt depois que acaba de ver la cas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@esteseverino na verdade eles se comunicavam p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n√£o t√¥ chorando horrores com o final de la cas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevante\n",
       "0  vou assistir a √∫ltima temperada de la casa de ...          1\n",
       "1  s√≥ quero chegar em casa e me entupir de brigad...          1\n",
       "2  toda vez, a gnt depois que acaba de ver la cas...          0\n",
       "3  @esteseverino na verdade eles se comunicavam p...          1\n",
       "4  n√£o t√¥ chorando horrores com o final de la cas...          0"
      ]
     },
<<<<<<< HEAD
=======
     "execution_count": 127,
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
     "metadata": {},
     "execution_count": 130
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nessa parte do projeto √© necess√°rio categorizar a opini√£o daqueles coment√°rios no twitter relativos √† aprova√ß√£o da s√©rie, (mais precisamente da nova temporada).\n",
    "\n",
    "Assim, foram encontrados diversos tweets, sendo alguns destes demasiadamente vagos, onde n√£o dava para discernir se era um coment√°rio aprovando ou n√£o da s√©rie La casa de papel. Nesse caso, foi considerado relevante apenas os coment√°rios que deixavam claro a critica √† s√©rie. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Fun√ß√µes utilizadas!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 131,
=======
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\arthu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
   "source": [
    "# FUN√á√ïES AUXILIARES DO SISTEMA para a montagem da base de dados do treinamento\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;\\/)|,''\"\"‚Äú‚Äù@#(*]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed.lower()\n",
    "\n",
    "# fun√ß√£o copiada do seguinte link: https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python\n",
    "def remove_emoji(string):\n",
    "    return emoji.get_emoji_regexp().sub(u'', string)\n",
    "\n",
    "# baixando as preposi√ß√µes\n",
    "nltk.download('stopwords')\n",
    "# definindo as preposi√ß√µes da lingua portuguesa\n",
    "stop = nltk.corpus.stopwords.words('portuguese')\n",
    "def segunda_limpeza(lis_tweet):\n",
    "    limpo = []\n",
    "    for pal in lis_tweet:\n",
    "        # al√©m de verificar se a palavra n√£o √© uma preposi√ß√£o vamos pegar s√≥ as que tem mais de 3 letras\n",
    "        # vamos aproveitar que estamos percorrendo cada palavra e remover os emojis nesse processo\n",
    "        if pal not in stop and len(pal)>3:\n",
    "            pal = remove_emoji(pal)\n",
    "            # pode ser que a palavra seja s√≥ o emoji, vamos verificar o tamanho dela de novo,\n",
    "            # pois pode ser uma palavra vazia\n",
    "            if len(pal) > 3:\n",
    "                limpo.append(pal)\n",
    "        else:\n",
    "            pass\n",
    "    return limpo\n",
    "\n",
    "def frase_para_palavras(df):\n",
    "    '''\n",
    "    fun√ß√£o para percorrer linha a linha uma coluna do dataframe e concatenar as palavras em uma unica lista\n",
    "    para ser usada no value_counts()\n",
    "    '''\n",
    "    data = ''\n",
    "    \n",
    "    for tweet in df:\n",
    "        # o tweet √© a frase que a pessoa postou, que se encontra em cada linha da nossa coluna\n",
    "        data += tweet\n",
    "        \n",
    "    # dando o split agora, para separar por virgula\n",
    "    data = data.split()\n",
    "    # data √© um vetor, podemos chamar a fun√ß√£o de tirar preposi√ß√£o aqui\n",
    "    data = segunda_limpeza(data)\n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "\n",
    "\n",
    "## Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O classificador Naive-Bayes √© da fam√≠lia de classificadores estat√≠sticos baseado no Teorema de Bayes, sendo utilizado para prever a ocorr√™ncia em um texto, muito √∫til para esse trabalho j√° que estamos tratando uma sequ√™ncia de tweets sobre o tema em quest√£o \"La casa de papel\". \n",
    "\n",
    "Assim, esse classificador, ao ter um conhecimento pr√©vio das condi√ß√µes - aqui dadas por relevante (1) e irrelevante (0) -  utiliza da frequ√™ncia de palavras para fazer sua classifica√ß√£o, j√° que ele trata cada palavra de uma frase como um termo independente, como por exemplo: \"la casa de papel √© muito bom\" √© equivalente a \"√© muito bom la casa de papel\".\n",
    "\n",
    "### O teorema de Bayes e as probabilidades independentes:\n",
    "\"Os eventos A e B s√£o independentes quando o fato de ter conhecimento sobre a ocorr√™ncia de A n√£o altera a expectativa sobre a probabilidade de ocorr√™ncia do evento B.\"\n",
    "\n",
    "Isso √© muito √∫til para o nosso modelo j√° que a probabilidade de que as mesmas frases sejam ditas em postagens distintas no twitter √© baixa, mas ao fazer a suposi√ß√£o de que cada palavra em uma frase atua de forma independente √© poss√≠vel se realizar os c√°lculos de probabilidade.\n",
    "\n",
    "### C√°lculos de probabilidade\n",
    "\n",
    "- legenda:\n",
    "\n",
    "    - $P(rel)$: probabilidade do post ser relevante;\n",
    "\n",
    "    - $P(irrel)$: probabilidade do post ser irrelevante;\n",
    "\n",
    "    - $P(total)$: $P(rel)$ + $P(irrel)$\n",
    "\n",
    "    - $P(rel|total)$: \n",
    "    $$P(rel|total) = \\frac{P(total|rel) P(rel)}{P(total)}$$\n",
    "    \n",
    "    - $P(irrel|total)$: \n",
    "    $$P(irrel|total) = \\frac{P(total|irrel) P(irrel)}{P(total)}$$\n",
    "\n",
    "#### Suaviza√ß√£o de Laplace\n",
    "Pelo c√°lculo das probabilidades independentes tem-se que, a partir de uma palavra, descobrir qual √© a probabilidade de essa palavra est√° na base de dados a partir de sua frequ√™ncia. Agora imagine que a palavra n√£o est√° na base de dados... o que ocorre √© que a probabilidade √© zero, e ao realizar a multiplica√ß√£o dos termos, o c√°lculo √© anulado, n√£o gerando nenhuma informa√ß√£o (o contr√°rio do que se espera).\n",
    "\n",
    "Assim, a suaviza√ß√£o de Laplace surge para prevenir esse caso, dado que √© adicionado 1 a cada contagem, para que o denominador nunca fique nulo. Em contrapartida, √© tamb√©m adicionado o n√∫mero de palavras totais ao divisor, o que leva a, ao realizar a divis√£o, gerar sempre um n√∫mero menor que um. \n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 132,
=======
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
   "source": [
    "#convertendo em vari√°veis categ√≥ricas:\n",
    "train['Treinamento'] = train['Treinamento'].astype('category')\n",
    "test['Teste'] = test['Teste'].astype('category')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 133,
=======
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
   "source": [
    "#limpando pontua√ß√µes do dataframe\n",
    "train['Clean']=train['Treinamento'].apply(cleanup)\n",
    "test['Clean']=test['Teste'].apply(cleanup)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 134,
   "source": [
    "test"
   ],
=======
   "execution_count": 153,
   "metadata": {},
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vou assistir a √∫ltima temperada de la casa de ...</td>\n",
       "      <td>1</td>\n",
       "      <td>vou assistir a √∫ltima temperada de la casa de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s√≥ quero chegar em casa e me entupir de brigad...</td>\n",
       "      <td>1</td>\n",
       "      <td>s√≥ quero chegar em casa e me entupir de brigad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>toda vez, a gnt depois que acaba de ver la cas...</td>\n",
       "      <td>0</td>\n",
       "      <td>toda vez a gnt depois que acaba de ver la casa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@esteseverino na verdade eles se comunicavam p...</td>\n",
       "      <td>1</td>\n",
       "      <td>esteseverino na verdade eles se comunicavam pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n√£o t√¥ chorando horrores com o final de la cas...</td>\n",
       "      <td>0</td>\n",
       "      <td>n√£o t√¥ chorando horrores com o final de la cas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>acabei la casa de papel</td>\n",
       "      <td>0</td>\n",
       "      <td>acabei la casa de papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>precisamos conversar sobre o final dessa tempo...</td>\n",
       "      <td>0</td>\n",
       "      <td>precisamos conversar sobre o final dessa tempo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>eu odeio l√° casa de papel, mataram a t√≥quio va...</td>\n",
       "      <td>1</td>\n",
       "      <td>eu odeio l√° casa de papel mataram a t√≥quio vai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>pregui√ßa de ver essa parte 5 de la casa de papel</td>\n",
       "      <td>0</td>\n",
       "      <td>pregui√ßa de ver essa parte 5 de la casa de papel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>la casa de papel n√£o vai acabar nunca? n√£o agu...</td>\n",
       "      <td>1</td>\n",
       "      <td>la casa de papel n√£o vai acabar nunca n√£o ague...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Relevante  \\\n",
       "0    vou assistir a √∫ltima temperada de la casa de ...          1   \n",
       "1    s√≥ quero chegar em casa e me entupir de brigad...          1   \n",
       "2    toda vez, a gnt depois que acaba de ver la cas...          0   \n",
       "3    @esteseverino na verdade eles se comunicavam p...          1   \n",
       "4    n√£o t√¥ chorando horrores com o final de la cas...          0   \n",
       "..                                                 ...        ...   \n",
       "195                            acabei la casa de papel          0   \n",
       "196  precisamos conversar sobre o final dessa tempo...          0   \n",
       "197  eu odeio l√° casa de papel, mataram a t√≥quio va...          1   \n",
       "198   pregui√ßa de ver essa parte 5 de la casa de papel          0   \n",
       "199  la casa de papel n√£o vai acabar nunca? n√£o agu...          1   \n",
       "\n",
       "                                                 Clean  \n",
       "0    vou assistir a √∫ltima temperada de la casa de ...  \n",
       "1    s√≥ quero chegar em casa e me entupir de brigad...  \n",
       "2    toda vez a gnt depois que acaba de ver la casa...  \n",
       "3    esteseverino na verdade eles se comunicavam pe...  \n",
       "4    n√£o t√¥ chorando horrores com o final de la cas...  \n",
       "..                                                 ...  \n",
       "195                            acabei la casa de papel  \n",
       "196  precisamos conversar sobre o final dessa tempo...  \n",
       "197  eu odeio l√° casa de papel mataram a t√≥quio vai...  \n",
       "198   pregui√ßa de ver essa parte 5 de la casa de papel  \n",
       "199  la casa de papel n√£o vai acabar nunca n√£o ague...  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
<<<<<<< HEAD
=======
     "execution_count": 153,
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
     "metadata": {},
     "execution_count": 134
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 135,
=======
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
   "source": [
    "# post relevante\n",
    "post_rel = train.loc[(train['Relevante'] == 1)]\n",
    "# post irrelevante\n",
    "post_irrel = train.loc[(train['Relevante'] == 0)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 136,
=======
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1214\n",
      "906\n",
      "2120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "886            moto\n",
       "887        guardada\n",
       "888        deitad√£o\n",
       "889           vendo\n",
       "890            casa\n",
       "891           papel\n",
       "892       trabalhar\n",
       "893          recebi\n",
       "894         spoiler\n",
       "895            casa\n",
       "896           papel\n",
       "897           quero\n",
       "898         cometer\n",
       "899    homic√≠diovou\n",
       "900      aproveitar\n",
       "901           novos\n",
       "902       epis√≥dios\n",
       "903            casa\n",
       "904           papel\n",
       "905      abafadinha\n",
       "dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
   "source": [
    "# agora precisamos quebrar o texto em palavras, usando a fun√ß√£o aux que converter frase em palavras,\n",
    "# ao mesmo tempo, vamos retirar as preposi√ß√µes do c√≥digo, paralelamente a convers√£o, melhorando a base de dados, temos:\n",
    "data_rel   = frase_para_palavras(post_rel['Clean'])\n",
    "data_irrel = frase_para_palavras(post_irrel['Clean'])\n",
    "\n",
    "# criando a serie dos posts relevantes e irrelevantes\n",
    "serie_rel = pd.Series(data_rel)\n",
    "serie_irrel = pd.Series(data_irrel)\n",
    "# Formando uma base de daddos com todas as palavras nele:\n",
    "data_total = data_rel + data_irrel\n",
    "\n",
    "#criando a serie com a base total de dados\n",
    "serie_total = pd.Series(data_total)\n",
    "\n",
    "print(len(serie_rel))\n",
    "print(len(serie_irrel))\n",
<<<<<<< HEAD
    "print(len(serie_total))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2476\n",
      "1910\n",
      "4386\n"
     ]
    }
   ],
   "metadata": {}
=======
    "print(len(serie_total))\n",
    "serie_irrel.tail(20)"
   ]
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Frequ√™ncias absolutas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Palavras em um texto s√£o vari√°veis **qualitativas nominais**, portanto usaremos `value_counts()` para obter a tabela de frequ√™ncias relativas e absolutas:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 137,
   "source": [
    "# construindo a tabela de relevante e irrelevante\n",
    "tabela_rel   = serie_rel.value_counts()\n",
    "tabela_irrel = serie_irrel.value_counts()\n",
    "tabela_total = serie_total.value_counts()\n",
    "lista_serie_total = serie_total.tolist()\n",
    "elementos_nao_repetidos = set(lista_serie_total)\n",
    "elementos_nao_repetidos = pd.DataFrame(elementos_nao_repetidos).value_counts()\n",
    "elementos_nao_repetidos"
   ],
=======
   "execution_count": 156,
   "metadata": {},
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "ü•∫ü•∫pra            1\n",
       "falando          1\n",
       "falecermaaano    1\n",
       "falta            1\n",
       "famosase         1\n",
       "                ..\n",
       "parecendo        1\n",
       "parei            1\n",
       "pariu            1\n",
       "pariuque         1\n",
       "100              1\n",
       "Length: 1210, dtype: int64"
      ]
     },
=======
       "100odeio         1\n",
       "papelia          1\n",
       "papelagora       1\n",
       "papelarturo      1\n",
       "papelassisti     1\n",
       "                ..\n",
       "facebook         1\n",
       "falando          1\n",
       "falar            1\n",
       "falecermaaano    1\n",
       "√∫nico            1\n",
       "Length: 952, dtype: int64"
      ]
     },
     "execution_count": 156,
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
     "metadata": {},
     "execution_count": 137
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 138,
   "source": [
    "# postagens relevantes\n",
    "post_rel.head()"
   ],
=======
   "execution_count": 157,
   "metadata": {},
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>Clean</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coisas q ser√£o proibidas quando eu for preside...</td>\n",
       "      <td>1</td>\n",
       "      <td>coisas q ser√£o proibidas quando eu for preside...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agr que t√¥ terminando de assistir la casa de p...</td>\n",
       "      <td>1</td>\n",
       "      <td>agr que t√¥ terminando de assistir la casa de p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>olha, quem me segue aqui sabe o tanto que odei...</td>\n",
       "      <td>1</td>\n",
       "      <td>olha quem me segue aqui sabe o tanto que odeio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>que final fdp do l√° casa de papel</td>\n",
       "      <td>1</td>\n",
       "      <td>que final fdp do l√° casa de papel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>final veio de l√° casa de papel, meu pai amado ...</td>\n",
       "      <td>1</td>\n",
       "      <td>final veio de l√° casa de papel meu pai amado o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevante  \\\n",
       "0  coisas q ser√£o proibidas quando eu for preside...          1   \n",
       "1  agr que t√¥ terminando de assistir la casa de p...          1   \n",
       "4  olha, quem me segue aqui sabe o tanto que odei...          1   \n",
       "6                  que final fdp do l√° casa de papel          1   \n",
       "8  final veio de l√° casa de papel, meu pai amado ...          1   \n",
       "\n",
       "                                               Clean  Classifica√ß√£o  \n",
       "0  coisas q ser√£o proibidas quando eu for preside...              0  \n",
       "1  agr que t√¥ terminando de assistir la casa de p...              0  \n",
       "4  olha quem me segue aqui sabe o tanto que odeio...              0  \n",
       "6                  que final fdp do l√° casa de papel              0  \n",
       "8  final veio de l√° casa de papel meu pai amado o...              0  "
      ]
     },
<<<<<<< HEAD
=======
     "execution_count": 157,
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
     "metadata": {},
     "execution_count": 138
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 139,
   "source": [
    "# postagens irrelevantes\n",
    "post_irrel.head()"
   ],
=======
   "execution_count": 158,
   "metadata": {},
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>Clean</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paguem minha terapia (la casa de papel vc me p...</td>\n",
       "      <td>0</td>\n",
       "      <td>paguem minha terapia la casa de papel vc me paga</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to com pena de terminar la casa de papel</td>\n",
       "      <td>0</td>\n",
       "      <td>to com pena de terminar la casa de papel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>simplesmente devastada com esse final da 1¬∞ pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>simplesmente devastada com esse final da 1¬∞ pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ai la casa de papel me mata pqp</td>\n",
       "      <td>0</td>\n",
       "      <td>ai la casa de papel me mata pqp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>criadores de l√° casa de papel deixaram mto na ...</td>\n",
       "      <td>0</td>\n",
       "      <td>criadores de l√° casa de papel deixaram mto na ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Treinamento  Relevante  \\\n",
       "2   paguem minha terapia (la casa de papel vc me p...          0   \n",
       "3            to com pena de terminar la casa de papel          0   \n",
       "5   simplesmente devastada com esse final da 1¬∞ pa...          0   \n",
       "7                     ai la casa de papel me mata pqp          0   \n",
       "10  criadores de l√° casa de papel deixaram mto na ...          0   \n",
       "\n",
       "                                                Clean  Classifica√ß√£o  \n",
       "2    paguem minha terapia la casa de papel vc me paga              0  \n",
       "3            to com pena de terminar la casa de papel              0  \n",
       "5   simplesmente devastada com esse final da 1¬∞ pa...              0  \n",
       "7                     ai la casa de papel me mata pqp              0  \n",
       "10  criadores de l√° casa de papel deixaram mto na ...              0  "
      ]
     },
<<<<<<< HEAD
=======
     "execution_count": 158,
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
     "metadata": {},
     "execution_count": 139
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 140,
   "source": [
    "p_rel = len(serie_rel)/len(serie_total)\n",
    "print('A probabilidade de relevantes √©: {0:.3f}'.format(p_rel))"
   ],
=======
   "execution_count": 159,
   "metadata": {},
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A probabilidade de relevantes √©: 0.573\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 141,
   "source": [
    "p_irrel = len(serie_irrel)/len(serie_total)\r\n",
    "print('A probabilidade de irrelevate √©: {0:.3f}'.format(p_irrel))"
   ],
=======
   "execution_count": 160,
   "metadata": {},
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A probabilidade de irrelevate √©: 0.427\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fun√ß√µes auxiliares para a suaviza√ß√£o de la place"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 142,
   "source": [
    "def quantas_vezes_aparece_palavra(palavra,tabela):\r\n",
    "    # a fun√ß√£o retorna o valor de vezes que a palavra aparece no seu conjunto\r\n",
    "    # por exemplo, quantas vezes aparece na tabela relevante?\r\n",
    "    # fazemos: num = tabela_rel['palavra']\r\n",
    "    # e retornamos esse valor\r\n",
    "    # por outro lado, pode n√£o ter a palavra, por isso a suavia√ß√£o de la place, quando isso ocorrer,\r\n",
    "    # vamos retornar 0\r\n",
    "    try:\r\n",
    "        # caso em que a palavra tem na tabela de frequencias\r\n",
    "        quant = tabela[palavra]\r\n",
    "        return quant\r\n",
    "    except:\r\n",
    "        # aqui a palavra n√£o est√° na tabela de frequencias,retornamos 0\r\n",
    "        return 0\r\n",
    "    \r\n",
    "def laplace_smoothing(palavras_da_classe,quantidade):\r\n",
    "    # vamos aplicar a formula da suaviza√ß√£o\r\n",
    "    num = quantidade + 1\r\n",
    "    den = len(palavras_da_classe) + len(elementos_nao_repetidos)\r\n",
    "    laplace = num/den\r\n",
    "    return laplace\r\n",
    "\r\n",
    "def p_tweet(tweet,relevante):\r\n",
    "    # se relevante for true, calcula para relevante\r\n",
    "    # se for false, para irrelevante\r\n",
    "    p = 1\r\n",
    "    # quebrando o tweet a cada espa√ßo \r\n",
    "    tweet_em_palavras = tweet.split()\r\n",
    "    \r\n",
    "    for palavra in tweet_em_palavras:\r\n",
    "        # vamos calcular o valor da frequencia absoluta da palavra\r\n",
    "        # para isto, usaremos a funcao quantas_vezes_aparece_palavra\r\n",
    "        # verificando qual classe queremos calcular p\r\n",
    "        \r\n",
    "        if relevante:\r\n",
    "            quant = quantas_vezes_aparece_palavra(palavra,tabela_rel)\r\n",
    "            p_palavra = laplace_smoothing(serie_rel,quant)\r\n",
    "            \r\n",
    "        else:\r\n",
    "            quant = quantas_vezes_aparece_palavra(palavra,tabela_irrel)\r\n",
    "            p_palavra = laplace_smoothing(serie_irrel,quant)\r\n",
    "            \r\n",
    "        p *= p_palavra\r\n",
    "    return p\r\n",
    "\r\n",
    "def rel_ou_irrel(tweet):\r\n",
    "    # vamos decidir se o tweet √© relevante ou n√£o\r\n",
    "    # para tal vamos aplicar o teorema de bayes\r\n",
    "    P_tweet_rel   = p_tweet(tweet,True)\r\n",
    "    P_tweet_irrel = p_tweet(tweet,False)\r\n",
    "    rel_bayes     = P_tweet_rel*p_rel\r\n",
    "    irrel_bayes   = P_tweet_irrel*p_irrel\r\n",
    "    # vamos usar o mesmo criterio adotado na tabela, 1 para relevante e 0 para irrelevante\r\n",
    "    if rel_bayes > irrel_bayes:\r\n",
    "        return 1\r\n",
    "    else:\r\n",
=======
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantas_vezes_aparece_palavra(palavra,tabela):\n",
    "    # a fun√ß√£o retorna o valor de vezes que a palavra aparece no seu conjunto\n",
    "    # por exemplo, quantas vezes aparece na tabela relevante?\n",
    "    # fazemos: num = tabela_rel['palavra']\n",
    "    # e retornamos esse valor\n",
    "    # por outro lado, pode n√£o ter a palavra, por isso a suavia√ß√£o de la place, quando isso ocorrer,\n",
    "    # vamos retornar 0\n",
    "    try:\n",
    "        # caso em que a palavra tem na tabela de frequencias\n",
    "        quant = tabela['palavra']\n",
    "        return quant\n",
    "    except:\n",
    "        # aqui a palavra n√£o est√° na tabela de frequencias,retornamos 0\n",
    "        return 0\n",
    "    \n",
    "def laplace_smoothing(palavras_da_classe,quantidade):\n",
    "    # vamos aplicar a formula da suaviza√ß√£o\n",
    "    num = quantidade + 1\n",
    "    den = len(palavras_da_classe) + len(elementos_nao_repetidos)\n",
    "    #den = 2193 + len(elementos_nao_repetidos)\n",
    "    laplace = num/den\n",
    "    return laplace\n",
    "\n",
    "def p_tweet(tweet,relevante):\n",
    "    # se relevante for true, calcula para relevante\n",
    "    # se for false, para irrelevante\n",
    "    p = 1\n",
    "    # quebrando o tweet a cada espa√ßo \n",
    "    tweet_em_palavras = tweet.split()\n",
    "    \n",
    "    for palavra in tweet_em_palavras:\n",
    "        # vamos calcular o valor da frequencia absoluta da palavra\n",
    "        # para isto, usaremos a funcao quantas_vezes_aparece_palavra\n",
    "        # verificando qual classe queremos calcular p\n",
    "        \n",
    "        if relevante:\n",
    "            quant = quantas_vezes_aparece_palavra(palavra,tabela_rel)\n",
    "            p_palavra = laplace_smoothing(serie_rel,quant)\n",
    "            \n",
    "        else:\n",
    "            quant = quantas_vezes_aparece_palavra(palavra,tabela_irrel)\n",
    "            p_palavra = laplace_smoothing(serie_irrel,quant)\n",
    "            \n",
    "        p *= p_palavra\n",
    "    return p\n",
    "\n",
    "def rel_ou_irrel(tweet):\n",
    "    # vamos decidir se o tweet √© relevante ou n√£o\n",
    "    # para tal vamos aplicar o teorema de bayes\n",
    "    P_tweet_rel   = p_tweet(tweet,True)\n",
    "    P_tweet_irrel = p_tweet(tweet,False)\n",
    "    rel_bayes     = P_tweet_rel*p_rel\n",
    "    irrel_bayes   = P_tweet_irrel*p_irrel\n",
    "    #print(rel_bayes,irrel_bayes)\n",
    "    # vamos usar o mesmo criterio adotado na tabela, 1 para relevante e 0 para irrelevante\n",
    "    if rel_bayes > irrel_bayes:\n",
    "        return 1\n",
    "    else:\n",
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
    "        return 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 143,
   "source": [
    "# agora vamos criar uma coluna nova, com a classifica√ß√£o dos tweets\r\n",
    "train['Classifica√ß√£o'] = train['Clean'].apply(rel_ou_irrel)\r\n",
    "train.loc[train['Classifica√ß√£o'] == 0]"
   ],
=======
   "execution_count": 162,
   "metadata": {},
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>Clean</th>\n",
       "      <th>Classifica√ß√£o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>2</th>\n",
       "      <td>paguem minha terapia (la casa de papel vc me p...</td>\n",
       "      <td>0</td>\n",
       "      <td>paguem minha terapia la casa de papel vc me paga</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>simplesmente devastada com esse final da 1¬∞ pa...</td>\n",
       "      <td>0</td>\n",
       "      <td>simplesmente devastada com esse final da 1¬∞ pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ai la casa de papel me mata pqp</td>\n",
       "      <td>0</td>\n",
       "      <td>ai la casa de papel me mata pqp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>criadores de l√° casa de papel deixaram mto na ...</td>\n",
       "      <td>0</td>\n",
       "      <td>criadores de l√° casa de papel deixaram mto na ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>n√£o tenho paci√™ncia para essas cenas aleat√≥ria...</td>\n",
       "      <td>0</td>\n",
       "      <td>n√£o tenho paci√™ncia para essas cenas aleat√≥ria...</td>\n",
=======
       "      <th>0</th>\n",
       "      <td>coisas q ser√£o proibidas quando eu for preside...</td>\n",
       "      <td>1</td>\n",
       "      <td>coisas q ser√£o proibidas quando eu for preside...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agr que t√¥ terminando de assistir la casa de p...</td>\n",
       "      <td>1</td>\n",
       "      <td>agr que t√¥ terminando de assistir la casa de p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paguem minha terapia (la casa de papel vc me p...</td>\n",
       "      <td>0</td>\n",
       "      <td>paguem minha terapia la casa de papel vc me paga</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to com pena de terminar la casa de papel</td>\n",
       "      <td>0</td>\n",
       "      <td>to com pena de terminar la casa de papel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>olha, quem me segue aqui sabe o tanto que odei...</td>\n",
       "      <td>1</td>\n",
       "      <td>olha quem me segue aqui sabe o tanto que odeio...</td>\n",
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>289</th>\n",
       "      <td>5 epis√≥dios na parte 5 da la casa de papel √© p...</td>\n",
       "      <td>1</td>\n",
       "      <td>5 epis√≥dios na parte 5 da la casa de papel √© p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>ai gnt  vo ver la casa de papel mesmo vou tent...</td>\n",
       "      <td>0</td>\n",
       "      <td>ai gnt  vo ver la casa de papel mesmo vou tent...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>ja estava com a moto guardada , deitad√£o vendo...</td>\n",
       "      <td>0</td>\n",
       "      <td>ja estava com a moto guardada  deitad√£o vendo ...</td>\n",
=======
       "      <th>295</th>\n",
       "      <td>m√≥ sacanagem esse final de la casa de papel</td>\n",
       "      <td>1</td>\n",
       "      <td>m√≥ sacanagem esse final de la casa de papel</td>\n",
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>recebi spoiler de la casa de papel e quero com...</td>\n",
       "      <td>0</td>\n",
       "      <td>recebi spoiler de la casa de papel e quero com...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
<<<<<<< HEAD
=======
       "      <th>297</th>\n",
       "      <td>terminei la casa de papel e me tornei o homem ...</td>\n",
       "      <td>1</td>\n",
       "      <td>terminei la casa de papel e me tornei o homem ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
       "      <th>298</th>\n",
       "      <td>vou aproveitar pra ver os novos epis√≥dios de l...</td>\n",
       "      <td>0</td>\n",
       "      <td>vou aproveitar pra ver os novos epis√≥dios de l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
<<<<<<< HEAD
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows √ó 4 columns</p>\n",
=======
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>terminei de assistir l√° casa de papel ,algu√©m ...</td>\n",
       "      <td>1</td>\n",
       "      <td>terminei de assistir l√° casa de papel algu√©m p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows √ó 4 columns</p>\n",
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Relevante  \\\n",
<<<<<<< HEAD
       "2    paguem minha terapia (la casa de papel vc me p...          0   \n",
       "5    simplesmente devastada com esse final da 1¬∞ pa...          0   \n",
       "7                      ai la casa de papel me mata pqp          0   \n",
       "10   criadores de l√° casa de papel deixaram mto na ...          0   \n",
       "11   n√£o tenho paci√™ncia para essas cenas aleat√≥ria...          0   \n",
       "..                                                 ...        ...   \n",
       "289  5 epis√≥dios na parte 5 da la casa de papel √© p...          1   \n",
       "291  ai gnt  vo ver la casa de papel mesmo vou tent...          0   \n",
       "293  ja estava com a moto guardada , deitad√£o vendo...          0   \n",
       "296  recebi spoiler de la casa de papel e quero com...          0   \n",
       "298  vou aproveitar pra ver os novos epis√≥dios de l...          0   \n",
       "\n",
       "                                                 Clean  Classifica√ß√£o  \n",
       "2     paguem minha terapia la casa de papel vc me paga              0  \n",
       "5    simplesmente devastada com esse final da 1¬∞ pa...              0  \n",
       "7                      ai la casa de papel me mata pqp              0  \n",
       "10   criadores de l√° casa de papel deixaram mto na ...              0  \n",
       "11   n√£o tenho paci√™ncia para essas cenas aleat√≥ria...              0  \n",
       "..                                                 ...            ...  \n",
       "289  5 epis√≥dios na parte 5 da la casa de papel √© p...              0  \n",
       "291  ai gnt  vo ver la casa de papel mesmo vou tent...              0  \n",
       "293  ja estava com a moto guardada  deitad√£o vendo ...              0  \n",
       "296  recebi spoiler de la casa de papel e quero com...              0  \n",
       "298  vou aproveitar pra ver os novos epis√≥dios de l...              0  \n",
       "\n",
       "[113 rows x 4 columns]"
      ]
     },
=======
       "0    coisas q ser√£o proibidas quando eu for preside...          1   \n",
       "1    agr que t√¥ terminando de assistir la casa de p...          1   \n",
       "2    paguem minha terapia (la casa de papel vc me p...          0   \n",
       "3             to com pena de terminar la casa de papel          0   \n",
       "4    olha, quem me segue aqui sabe o tanto que odei...          1   \n",
       "..                                                 ...        ...   \n",
       "295        m√≥ sacanagem esse final de la casa de papel          1   \n",
       "296  recebi spoiler de la casa de papel e quero com...          0   \n",
       "297  terminei la casa de papel e me tornei o homem ...          1   \n",
       "298  vou aproveitar pra ver os novos epis√≥dios de l...          0   \n",
       "299  terminei de assistir l√° casa de papel ,algu√©m ...          1   \n",
       "\n",
       "                                                 Clean  Classifica√ß√£o  \n",
       "0    coisas q ser√£o proibidas quando eu for preside...              0  \n",
       "1    agr que t√¥ terminando de assistir la casa de p...              0  \n",
       "2     paguem minha terapia la casa de papel vc me paga              0  \n",
       "3             to com pena de terminar la casa de papel              0  \n",
       "4    olha quem me segue aqui sabe o tanto que odeio...              0  \n",
       "..                                                 ...            ...  \n",
       "295        m√≥ sacanagem esse final de la casa de papel              0  \n",
       "296  recebi spoiler de la casa de papel e quero com...              0  \n",
       "297  terminei la casa de papel e me tornei o homem ...              0  \n",
       "298  vou aproveitar pra ver os novos epis√≥dios de l...              0  \n",
       "299  terminei de assistir l√° casa de papel algu√©m p...              0  \n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 162,
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
     "metadata": {},
     "execution_count": 143
    }
   ],
<<<<<<< HEAD
   "metadata": {}
=======
   "source": [
    "# agora vamos criar uma coluna nova, com a classifica√ß√£o dos tweets\n",
    "train['Classifica√ß√£o'] = train['Clean'].apply(rel_ou_irrel)\n",
    "train"
   ]
>>>>>>> ff32db29a9a51b74a60cf9f8884479e2392260e1
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Concluindo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Refer√™ncias"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a036e081e21c160afc26bb4b03f978afee4695dfefad222ea89752b41a5783e0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}